{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hpdbman/.conda/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 100)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import *\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_classes = 100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), input_shape=(32, 32, 3), padding='same', activation='relu',\n",
    "                 kernel_initializer='uniform'))\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 2), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu', kernel_initializer='uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "adam = Adam(lr=1e-5) #1e-5收敛慢\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 4.5655 - accuracy: 0.0134 - val_loss: 4.4068 - val_accuracy: 0.0253\n",
      "Epoch 2/300\n",
      "391/391 [==============================] - 37s 93ms/step - loss: 4.3239 - accuracy: 0.0308 - val_loss: 4.2046 - val_accuracy: 0.0455\n",
      "Epoch 3/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 4.1798 - accuracy: 0.0468 - val_loss: 4.0683 - val_accuracy: 0.0680\n",
      "Epoch 4/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 4.0710 - accuracy: 0.0629 - val_loss: 3.9805 - val_accuracy: 0.0851\n",
      "Epoch 5/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.9895 - accuracy: 0.0773 - val_loss: 3.8910 - val_accuracy: 0.1003\n",
      "Epoch 6/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.9048 - accuracy: 0.0912 - val_loss: 3.7753 - val_accuracy: 0.1208\n",
      "Epoch 7/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.8215 - accuracy: 0.1066 - val_loss: 3.7085 - val_accuracy: 0.1310\n",
      "Epoch 8/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.7541 - accuracy: 0.1190 - val_loss: 3.6544 - val_accuracy: 0.1420\n",
      "Epoch 9/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.6898 - accuracy: 0.1306 - val_loss: 3.5722 - val_accuracy: 0.1534\n",
      "Epoch 10/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.6292 - accuracy: 0.1404 - val_loss: 3.5120 - val_accuracy: 0.1646\n",
      "Epoch 11/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.5677 - accuracy: 0.1516 - val_loss: 3.4493 - val_accuracy: 0.1793\n",
      "Epoch 12/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.5100 - accuracy: 0.1615 - val_loss: 3.4162 - val_accuracy: 0.1827\n",
      "Epoch 13/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.4671 - accuracy: 0.1690 - val_loss: 3.3859 - val_accuracy: 0.1835\n",
      "Epoch 14/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.4284 - accuracy: 0.1775 - val_loss: 3.3220 - val_accuracy: 0.1999\n",
      "Epoch 15/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.3833 - accuracy: 0.1830 - val_loss: 3.2902 - val_accuracy: 0.2089\n",
      "Epoch 16/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.3425 - accuracy: 0.1910 - val_loss: 3.2610 - val_accuracy: 0.2113\n",
      "Epoch 17/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.3046 - accuracy: 0.1998 - val_loss: 3.2172 - val_accuracy: 0.2179\n",
      "Epoch 18/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.2708 - accuracy: 0.2032 - val_loss: 3.2079 - val_accuracy: 0.2191\n",
      "Epoch 19/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.2424 - accuracy: 0.2095 - val_loss: 3.1672 - val_accuracy: 0.2264\n",
      "Epoch 20/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.2111 - accuracy: 0.2142 - val_loss: 3.1422 - val_accuracy: 0.2353\n",
      "Epoch 21/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.1774 - accuracy: 0.2222 - val_loss: 3.1490 - val_accuracy: 0.2297\n",
      "Epoch 22/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.1449 - accuracy: 0.2273 - val_loss: 3.0887 - val_accuracy: 0.2405\n",
      "Epoch 23/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.1190 - accuracy: 0.2322 - val_loss: 3.0840 - val_accuracy: 0.2444\n",
      "Epoch 24/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.0902 - accuracy: 0.2372 - val_loss: 3.0619 - val_accuracy: 0.2486\n",
      "Epoch 25/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.0685 - accuracy: 0.2419 - val_loss: 3.0720 - val_accuracy: 0.2457\n",
      "Epoch 26/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.0357 - accuracy: 0.2461 - val_loss: 3.0008 - val_accuracy: 0.2606\n",
      "Epoch 27/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 3.0079 - accuracy: 0.2517 - val_loss: 3.0131 - val_accuracy: 0.2563\n",
      "Epoch 28/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.9838 - accuracy: 0.2590 - val_loss: 2.9631 - val_accuracy: 0.2681\n",
      "Epoch 29/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.9587 - accuracy: 0.2626 - val_loss: 2.9556 - val_accuracy: 0.2715\n",
      "Epoch 30/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.9326 - accuracy: 0.2666 - val_loss: 2.9245 - val_accuracy: 0.2741\n",
      "Epoch 31/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.9050 - accuracy: 0.2717 - val_loss: 2.9111 - val_accuracy: 0.2802\n",
      "Epoch 32/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.8876 - accuracy: 0.2736 - val_loss: 2.8984 - val_accuracy: 0.2810\n",
      "Epoch 33/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.8613 - accuracy: 0.2795 - val_loss: 2.8756 - val_accuracy: 0.2866\n",
      "Epoch 34/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.8400 - accuracy: 0.2862 - val_loss: 2.8591 - val_accuracy: 0.2912\n",
      "Epoch 35/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.8155 - accuracy: 0.2894 - val_loss: 2.8383 - val_accuracy: 0.2925\n",
      "Epoch 36/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.7905 - accuracy: 0.2952 - val_loss: 2.8434 - val_accuracy: 0.2919\n",
      "Epoch 37/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.7662 - accuracy: 0.3011 - val_loss: 2.7985 - val_accuracy: 0.3051\n",
      "Epoch 38/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.7464 - accuracy: 0.3023 - val_loss: 2.7907 - val_accuracy: 0.3062\n",
      "Epoch 39/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.7301 - accuracy: 0.3065 - val_loss: 2.8017 - val_accuracy: 0.3017\n",
      "Epoch 40/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.7097 - accuracy: 0.3101 - val_loss: 2.7862 - val_accuracy: 0.3070\n",
      "Epoch 41/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.6848 - accuracy: 0.3138 - val_loss: 2.7623 - val_accuracy: 0.3109\n",
      "Epoch 42/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.6654 - accuracy: 0.3183 - val_loss: 2.7412 - val_accuracy: 0.3164\n",
      "Epoch 43/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.6429 - accuracy: 0.3235 - val_loss: 2.7470 - val_accuracy: 0.3140\n",
      "Epoch 44/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.6193 - accuracy: 0.3303 - val_loss: 2.7294 - val_accuracy: 0.3180\n",
      "Epoch 45/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.6082 - accuracy: 0.3313 - val_loss: 2.7298 - val_accuracy: 0.3216\n",
      "Epoch 46/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.5909 - accuracy: 0.3369 - val_loss: 2.7015 - val_accuracy: 0.3264\n",
      "Epoch 47/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.5633 - accuracy: 0.3401 - val_loss: 2.7564 - val_accuracy: 0.3122\n",
      "Epoch 48/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.5437 - accuracy: 0.3448 - val_loss: 2.6987 - val_accuracy: 0.3249\n",
      "Epoch 49/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.5331 - accuracy: 0.3474 - val_loss: 2.6969 - val_accuracy: 0.3235\n",
      "Epoch 50/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.5083 - accuracy: 0.3546 - val_loss: 2.6599 - val_accuracy: 0.3323\n",
      "Epoch 51/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.4897 - accuracy: 0.3562 - val_loss: 2.6554 - val_accuracy: 0.3384\n",
      "Epoch 52/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.4699 - accuracy: 0.3602 - val_loss: 2.6414 - val_accuracy: 0.3362\n",
      "Epoch 53/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.4501 - accuracy: 0.3637 - val_loss: 2.6476 - val_accuracy: 0.3401\n",
      "Epoch 54/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.4322 - accuracy: 0.3699 - val_loss: 2.6471 - val_accuracy: 0.3394\n",
      "Epoch 55/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.4140 - accuracy: 0.3726 - val_loss: 2.6179 - val_accuracy: 0.3479\n",
      "Epoch 56/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.4000 - accuracy: 0.3761 - val_loss: 2.6353 - val_accuracy: 0.3431\n",
      "Epoch 57/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.3752 - accuracy: 0.3791 - val_loss: 2.5970 - val_accuracy: 0.3475\n",
      "Epoch 58/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.3602 - accuracy: 0.3852 - val_loss: 2.6014 - val_accuracy: 0.3496\n",
      "Epoch 59/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.3416 - accuracy: 0.3861 - val_loss: 2.5940 - val_accuracy: 0.3540\n",
      "Epoch 60/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.3153 - accuracy: 0.3913 - val_loss: 2.5763 - val_accuracy: 0.3588\n",
      "Epoch 61/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.3009 - accuracy: 0.3965 - val_loss: 2.6177 - val_accuracy: 0.3494\n",
      "Epoch 62/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.2861 - accuracy: 0.3997 - val_loss: 2.5608 - val_accuracy: 0.3592\n",
      "Epoch 63/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.2686 - accuracy: 0.4022 - val_loss: 2.5588 - val_accuracy: 0.3594\n",
      "Epoch 64/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.2492 - accuracy: 0.4080 - val_loss: 2.5714 - val_accuracy: 0.3581\n",
      "Epoch 65/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.2333 - accuracy: 0.4100 - val_loss: 2.5540 - val_accuracy: 0.3612\n",
      "Epoch 66/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.2109 - accuracy: 0.4143 - val_loss: 2.5703 - val_accuracy: 0.3593\n",
      "Epoch 67/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.2000 - accuracy: 0.4178 - val_loss: 2.5369 - val_accuracy: 0.3630\n",
      "Epoch 68/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.1737 - accuracy: 0.4228 - val_loss: 2.5492 - val_accuracy: 0.3628\n",
      "Epoch 69/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.1566 - accuracy: 0.4264 - val_loss: 2.5586 - val_accuracy: 0.3608\n",
      "Epoch 70/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.1369 - accuracy: 0.4294 - val_loss: 2.5399 - val_accuracy: 0.3671\n",
      "Epoch 71/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.1188 - accuracy: 0.4343 - val_loss: 2.5458 - val_accuracy: 0.3672\n",
      "Epoch 72/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.1037 - accuracy: 0.4389 - val_loss: 2.5658 - val_accuracy: 0.3667\n",
      "Epoch 73/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.0852 - accuracy: 0.4438 - val_loss: 2.5232 - val_accuracy: 0.3726\n",
      "Epoch 74/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.0622 - accuracy: 0.4491 - val_loss: 2.5341 - val_accuracy: 0.3735\n",
      "Epoch 75/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.0457 - accuracy: 0.4491 - val_loss: 2.5272 - val_accuracy: 0.3728\n",
      "Epoch 76/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 2.0280 - accuracy: 0.4559 - val_loss: 2.5283 - val_accuracy: 0.3753\n",
      "Epoch 77/300\n",
      "391/391 [==============================] - 37s 93ms/step - loss: 2.0071 - accuracy: 0.4595 - val_loss: 2.5171 - val_accuracy: 0.3705\n",
      "Epoch 78/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.9922 - accuracy: 0.4642 - val_loss: 2.5119 - val_accuracy: 0.3786\n",
      "Epoch 79/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.9660 - accuracy: 0.4690 - val_loss: 2.5201 - val_accuracy: 0.3770\n",
      "Epoch 80/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.9593 - accuracy: 0.4703 - val_loss: 2.5356 - val_accuracy: 0.3730\n",
      "Epoch 81/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.9349 - accuracy: 0.4752 - val_loss: 2.5163 - val_accuracy: 0.3789\n",
      "Epoch 82/300\n",
      "391/391 [==============================] - 37s 93ms/step - loss: 1.9128 - accuracy: 0.4810 - val_loss: 2.5254 - val_accuracy: 0.3783\n",
      "Epoch 83/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.9012 - accuracy: 0.4837 - val_loss: 2.5079 - val_accuracy: 0.3805\n",
      "Epoch 84/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.8730 - accuracy: 0.4871 - val_loss: 2.5062 - val_accuracy: 0.3818\n",
      "Epoch 85/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.8635 - accuracy: 0.4919 - val_loss: 2.5108 - val_accuracy: 0.3819\n",
      "Epoch 86/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.8334 - accuracy: 0.4972 - val_loss: 2.5205 - val_accuracy: 0.3808\n",
      "Epoch 87/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.8204 - accuracy: 0.4982 - val_loss: 2.5136 - val_accuracy: 0.3889\n",
      "Epoch 88/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.7966 - accuracy: 0.5076 - val_loss: 2.5280 - val_accuracy: 0.3800\n",
      "Epoch 89/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.7790 - accuracy: 0.5102 - val_loss: 2.5484 - val_accuracy: 0.3798\n",
      "Epoch 90/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.7594 - accuracy: 0.5136 - val_loss: 2.5104 - val_accuracy: 0.3875\n",
      "Epoch 91/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.7371 - accuracy: 0.5178 - val_loss: 2.5528 - val_accuracy: 0.3854\n",
      "Epoch 92/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.7234 - accuracy: 0.5218 - val_loss: 2.5120 - val_accuracy: 0.3907\n",
      "Epoch 93/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.7036 - accuracy: 0.5271 - val_loss: 2.5154 - val_accuracy: 0.3886\n",
      "Epoch 94/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.6787 - accuracy: 0.5351 - val_loss: 2.5093 - val_accuracy: 0.3925\n",
      "Epoch 95/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.6662 - accuracy: 0.5342 - val_loss: 2.5122 - val_accuracy: 0.3909\n",
      "Epoch 96/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.6369 - accuracy: 0.5440 - val_loss: 2.5220 - val_accuracy: 0.3941\n",
      "Epoch 97/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.6304 - accuracy: 0.5469 - val_loss: 2.5083 - val_accuracy: 0.3905\n",
      "Epoch 98/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.5999 - accuracy: 0.5520 - val_loss: 2.5290 - val_accuracy: 0.3877\n",
      "Epoch 99/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.5796 - accuracy: 0.5561 - val_loss: 2.5267 - val_accuracy: 0.3895\n",
      "Epoch 100/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.5550 - accuracy: 0.5637 - val_loss: 2.5623 - val_accuracy: 0.3870\n",
      "Epoch 101/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.5443 - accuracy: 0.5670 - val_loss: 2.5479 - val_accuracy: 0.3890\n",
      "Epoch 102/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.5238 - accuracy: 0.5718 - val_loss: 2.5641 - val_accuracy: 0.3891\n",
      "Epoch 103/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.5042 - accuracy: 0.5727 - val_loss: 2.6048 - val_accuracy: 0.3904\n",
      "Epoch 104/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.4844 - accuracy: 0.5808 - val_loss: 2.5714 - val_accuracy: 0.3906\n",
      "Epoch 105/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.4625 - accuracy: 0.5841 - val_loss: 2.5660 - val_accuracy: 0.3943\n",
      "Epoch 106/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.4350 - accuracy: 0.5915 - val_loss: 2.5774 - val_accuracy: 0.3952\n",
      "Epoch 107/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.4254 - accuracy: 0.5942 - val_loss: 2.6055 - val_accuracy: 0.3917\n",
      "Epoch 108/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.4094 - accuracy: 0.5957 - val_loss: 2.5788 - val_accuracy: 0.3957\n",
      "Epoch 109/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.3898 - accuracy: 0.6020 - val_loss: 2.5809 - val_accuracy: 0.3964\n",
      "Epoch 110/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.3647 - accuracy: 0.6092 - val_loss: 2.5812 - val_accuracy: 0.3939\n",
      "Epoch 111/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.3524 - accuracy: 0.6116 - val_loss: 2.6612 - val_accuracy: 0.3859\n",
      "Epoch 112/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.3274 - accuracy: 0.6177 - val_loss: 2.5989 - val_accuracy: 0.3923\n",
      "Epoch 113/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.3085 - accuracy: 0.6223 - val_loss: 2.6358 - val_accuracy: 0.3968\n",
      "Epoch 114/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.2957 - accuracy: 0.6265 - val_loss: 2.6218 - val_accuracy: 0.3950\n",
      "Epoch 115/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.2721 - accuracy: 0.6331 - val_loss: 2.6667 - val_accuracy: 0.3903\n",
      "Epoch 116/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.2634 - accuracy: 0.6315 - val_loss: 2.6492 - val_accuracy: 0.3919\n",
      "Epoch 117/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.2324 - accuracy: 0.6407 - val_loss: 2.7379 - val_accuracy: 0.3835\n",
      "Epoch 118/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.2094 - accuracy: 0.6468 - val_loss: 2.6574 - val_accuracy: 0.3978\n",
      "Epoch 119/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.1980 - accuracy: 0.6473 - val_loss: 2.6726 - val_accuracy: 0.3979\n",
      "Epoch 120/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.1819 - accuracy: 0.6518 - val_loss: 2.6786 - val_accuracy: 0.3942\n",
      "Epoch 121/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.1611 - accuracy: 0.6563 - val_loss: 2.7211 - val_accuracy: 0.3946\n",
      "Epoch 122/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.1461 - accuracy: 0.6625 - val_loss: 2.7069 - val_accuracy: 0.3945\n",
      "Epoch 123/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.1262 - accuracy: 0.6662 - val_loss: 2.7313 - val_accuracy: 0.3911\n",
      "Epoch 124/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.1033 - accuracy: 0.6745 - val_loss: 2.7063 - val_accuracy: 0.3897\n",
      "Epoch 125/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.0940 - accuracy: 0.6755 - val_loss: 2.7688 - val_accuracy: 0.3906\n",
      "Epoch 126/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.0763 - accuracy: 0.6785 - val_loss: 2.7250 - val_accuracy: 0.3974\n",
      "Epoch 127/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.0465 - accuracy: 0.6900 - val_loss: 2.7680 - val_accuracy: 0.3943\n",
      "Epoch 128/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.0394 - accuracy: 0.6899 - val_loss: 2.7713 - val_accuracy: 0.3924\n",
      "Epoch 129/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.0306 - accuracy: 0.6900 - val_loss: 2.7972 - val_accuracy: 0.3950\n",
      "Epoch 130/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 1.0008 - accuracy: 0.7009 - val_loss: 2.7562 - val_accuracy: 0.3983\n",
      "Epoch 131/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.9946 - accuracy: 0.7025 - val_loss: 2.8278 - val_accuracy: 0.3944\n",
      "Epoch 132/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.9722 - accuracy: 0.7059 - val_loss: 2.7967 - val_accuracy: 0.3927\n",
      "Epoch 133/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.9613 - accuracy: 0.7117 - val_loss: 2.8152 - val_accuracy: 0.3973\n",
      "Epoch 134/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.9357 - accuracy: 0.7181 - val_loss: 2.8338 - val_accuracy: 0.3956\n",
      "Epoch 135/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.9261 - accuracy: 0.7193 - val_loss: 2.8816 - val_accuracy: 0.3936\n",
      "Epoch 136/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.9103 - accuracy: 0.7236 - val_loss: 2.8680 - val_accuracy: 0.3972\n",
      "Epoch 137/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.8917 - accuracy: 0.7280 - val_loss: 2.8953 - val_accuracy: 0.3910\n",
      "Epoch 138/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.8788 - accuracy: 0.7328 - val_loss: 2.9071 - val_accuracy: 0.3937\n",
      "Epoch 139/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.8590 - accuracy: 0.7389 - val_loss: 2.8697 - val_accuracy: 0.3924\n",
      "Epoch 140/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.8447 - accuracy: 0.7434 - val_loss: 2.8967 - val_accuracy: 0.3933\n",
      "Epoch 141/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.8315 - accuracy: 0.7460 - val_loss: 2.9130 - val_accuracy: 0.3954\n",
      "Epoch 142/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.8148 - accuracy: 0.7484 - val_loss: 2.9273 - val_accuracy: 0.3936\n",
      "Epoch 143/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.7957 - accuracy: 0.7561 - val_loss: 2.9436 - val_accuracy: 0.4000\n",
      "Epoch 144/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.7987 - accuracy: 0.7523 - val_loss: 2.9956 - val_accuracy: 0.3991\n",
      "Epoch 145/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.7725 - accuracy: 0.7634 - val_loss: 2.9892 - val_accuracy: 0.3918\n",
      "Epoch 146/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.7610 - accuracy: 0.7656 - val_loss: 3.0227 - val_accuracy: 0.3950\n",
      "Epoch 147/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.7369 - accuracy: 0.7707 - val_loss: 3.0256 - val_accuracy: 0.3959\n",
      "Epoch 148/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.7329 - accuracy: 0.7736 - val_loss: 2.9938 - val_accuracy: 0.3938\n",
      "Epoch 149/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.7159 - accuracy: 0.7768 - val_loss: 3.0143 - val_accuracy: 0.3960\n",
      "Epoch 150/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.7041 - accuracy: 0.7810 - val_loss: 3.1007 - val_accuracy: 0.3946\n",
      "Epoch 151/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.6925 - accuracy: 0.7868 - val_loss: 3.0549 - val_accuracy: 0.3965\n",
      "Epoch 152/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.6813 - accuracy: 0.7865 - val_loss: 3.1080 - val_accuracy: 0.3921\n",
      "Epoch 153/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.6654 - accuracy: 0.7934 - val_loss: 3.0200 - val_accuracy: 0.3953\n",
      "Epoch 154/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.6584 - accuracy: 0.7948 - val_loss: 3.1042 - val_accuracy: 0.3935\n",
      "Epoch 155/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.6471 - accuracy: 0.7965 - val_loss: 3.1551 - val_accuracy: 0.3968\n",
      "Epoch 156/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.6287 - accuracy: 0.8029 - val_loss: 3.1338 - val_accuracy: 0.3944\n",
      "Epoch 157/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.6264 - accuracy: 0.8022 - val_loss: 3.1584 - val_accuracy: 0.3901\n",
      "Epoch 158/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.6148 - accuracy: 0.8061 - val_loss: 3.1466 - val_accuracy: 0.3958\n",
      "Epoch 159/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5961 - accuracy: 0.8104 - val_loss: 3.1964 - val_accuracy: 0.3927\n",
      "Epoch 160/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5868 - accuracy: 0.8152 - val_loss: 3.2032 - val_accuracy: 0.3960\n",
      "Epoch 161/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5675 - accuracy: 0.8200 - val_loss: 3.2032 - val_accuracy: 0.3963\n",
      "Epoch 162/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5728 - accuracy: 0.8186 - val_loss: 3.2123 - val_accuracy: 0.3904\n",
      "Epoch 163/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5604 - accuracy: 0.8211 - val_loss: 3.2333 - val_accuracy: 0.4002\n",
      "Epoch 164/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5414 - accuracy: 0.8282 - val_loss: 3.2982 - val_accuracy: 0.3945\n",
      "Epoch 165/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5336 - accuracy: 0.8296 - val_loss: 3.2460 - val_accuracy: 0.3934\n",
      "Epoch 166/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5259 - accuracy: 0.8320 - val_loss: 3.2909 - val_accuracy: 0.3935\n",
      "Epoch 167/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5175 - accuracy: 0.8350 - val_loss: 3.2908 - val_accuracy: 0.3962\n",
      "Epoch 168/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.5117 - accuracy: 0.8363 - val_loss: 3.3397 - val_accuracy: 0.3967\n",
      "Epoch 169/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4981 - accuracy: 0.8393 - val_loss: 3.3633 - val_accuracy: 0.3929\n",
      "Epoch 170/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4913 - accuracy: 0.8425 - val_loss: 3.4364 - val_accuracy: 0.3926\n",
      "Epoch 171/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4862 - accuracy: 0.8448 - val_loss: 3.3735 - val_accuracy: 0.3883\n",
      "Epoch 172/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4861 - accuracy: 0.8429 - val_loss: 3.3770 - val_accuracy: 0.3959\n",
      "Epoch 173/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4665 - accuracy: 0.8493 - val_loss: 3.3930 - val_accuracy: 0.3971\n",
      "Epoch 174/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4621 - accuracy: 0.8494 - val_loss: 3.3785 - val_accuracy: 0.3971\n",
      "Epoch 175/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4504 - accuracy: 0.8530 - val_loss: 3.3890 - val_accuracy: 0.3968\n",
      "Epoch 176/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4394 - accuracy: 0.8585 - val_loss: 3.4036 - val_accuracy: 0.3976\n",
      "Epoch 177/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4398 - accuracy: 0.8577 - val_loss: 3.4606 - val_accuracy: 0.3903\n",
      "Epoch 178/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4170 - accuracy: 0.8647 - val_loss: 3.4648 - val_accuracy: 0.3893\n",
      "Epoch 179/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4228 - accuracy: 0.8640 - val_loss: 3.5009 - val_accuracy: 0.3974\n",
      "Epoch 180/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.4157 - accuracy: 0.8657 - val_loss: 3.5493 - val_accuracy: 0.3968\n",
      "Epoch 181/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3979 - accuracy: 0.8702 - val_loss: 3.5383 - val_accuracy: 0.3992\n",
      "Epoch 182/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3983 - accuracy: 0.8725 - val_loss: 3.4717 - val_accuracy: 0.4009\n",
      "Epoch 183/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3935 - accuracy: 0.8701 - val_loss: 3.5619 - val_accuracy: 0.3881\n",
      "Epoch 184/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3932 - accuracy: 0.8721 - val_loss: 3.5571 - val_accuracy: 0.3954\n",
      "Epoch 185/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3784 - accuracy: 0.8762 - val_loss: 3.5527 - val_accuracy: 0.3951\n",
      "Epoch 186/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3656 - accuracy: 0.8806 - val_loss: 3.5847 - val_accuracy: 0.3957\n",
      "Epoch 187/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3634 - accuracy: 0.8813 - val_loss: 3.6060 - val_accuracy: 0.3925\n",
      "Epoch 188/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3629 - accuracy: 0.8810 - val_loss: 3.6710 - val_accuracy: 0.3942\n",
      "Epoch 189/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3627 - accuracy: 0.8834 - val_loss: 3.5878 - val_accuracy: 0.3984\n",
      "Epoch 190/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3511 - accuracy: 0.8857 - val_loss: 3.6839 - val_accuracy: 0.3877\n",
      "Epoch 191/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3425 - accuracy: 0.8876 - val_loss: 3.6411 - val_accuracy: 0.3971\n",
      "Epoch 192/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3378 - accuracy: 0.8883 - val_loss: 3.6543 - val_accuracy: 0.3942\n",
      "Epoch 193/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3303 - accuracy: 0.8922 - val_loss: 3.7399 - val_accuracy: 0.3864\n",
      "Epoch 194/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3276 - accuracy: 0.8920 - val_loss: 3.7581 - val_accuracy: 0.3924\n",
      "Epoch 195/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3278 - accuracy: 0.8928 - val_loss: 3.7082 - val_accuracy: 0.3932\n",
      "Epoch 196/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3180 - accuracy: 0.8951 - val_loss: 3.7233 - val_accuracy: 0.3946\n",
      "Epoch 197/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3200 - accuracy: 0.8945 - val_loss: 3.7202 - val_accuracy: 0.3937\n",
      "Epoch 198/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3070 - accuracy: 0.9004 - val_loss: 3.7593 - val_accuracy: 0.3932\n",
      "Epoch 199/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3005 - accuracy: 0.9003 - val_loss: 3.7399 - val_accuracy: 0.3947\n",
      "Epoch 200/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3011 - accuracy: 0.9015 - val_loss: 3.7551 - val_accuracy: 0.3932\n",
      "Epoch 201/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.3015 - accuracy: 0.9014 - val_loss: 3.8083 - val_accuracy: 0.3950\n",
      "Epoch 202/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2928 - accuracy: 0.9038 - val_loss: 3.7647 - val_accuracy: 0.3943\n",
      "Epoch 203/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2831 - accuracy: 0.9076 - val_loss: 3.8019 - val_accuracy: 0.3887\n",
      "Epoch 204/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2846 - accuracy: 0.9058 - val_loss: 3.8315 - val_accuracy: 0.3925\n",
      "Epoch 205/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2731 - accuracy: 0.9103 - val_loss: 3.8188 - val_accuracy: 0.3959\n",
      "Epoch 206/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2874 - accuracy: 0.9064 - val_loss: 3.8977 - val_accuracy: 0.3958\n",
      "Epoch 207/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2710 - accuracy: 0.9110 - val_loss: 3.8059 - val_accuracy: 0.3968\n",
      "Epoch 208/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2686 - accuracy: 0.9123 - val_loss: 3.8475 - val_accuracy: 0.3926\n",
      "Epoch 209/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2711 - accuracy: 0.9108 - val_loss: 3.8274 - val_accuracy: 0.3953\n",
      "Epoch 210/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2566 - accuracy: 0.9158 - val_loss: 3.9216 - val_accuracy: 0.3920\n",
      "Epoch 211/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2604 - accuracy: 0.9146 - val_loss: 3.9088 - val_accuracy: 0.3928\n",
      "Epoch 212/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2506 - accuracy: 0.9179 - val_loss: 3.9619 - val_accuracy: 0.3944\n",
      "Epoch 213/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2486 - accuracy: 0.9192 - val_loss: 3.9067 - val_accuracy: 0.3944\n",
      "Epoch 214/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2529 - accuracy: 0.9167 - val_loss: 3.9505 - val_accuracy: 0.3954\n",
      "Epoch 215/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2423 - accuracy: 0.9213 - val_loss: 3.9404 - val_accuracy: 0.3973\n",
      "Epoch 216/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2381 - accuracy: 0.9219 - val_loss: 4.0030 - val_accuracy: 0.3941\n",
      "Epoch 217/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2406 - accuracy: 0.9216 - val_loss: 3.9125 - val_accuracy: 0.3998\n",
      "Epoch 218/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2336 - accuracy: 0.9237 - val_loss: 3.9441 - val_accuracy: 0.3998\n",
      "Epoch 219/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2281 - accuracy: 0.9250 - val_loss: 3.9062 - val_accuracy: 0.3924\n",
      "Epoch 220/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2372 - accuracy: 0.9229 - val_loss: 3.9698 - val_accuracy: 0.3948\n",
      "Epoch 221/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2245 - accuracy: 0.9254 - val_loss: 3.9640 - val_accuracy: 0.3961\n",
      "Epoch 222/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2251 - accuracy: 0.9261 - val_loss: 4.0325 - val_accuracy: 0.3975\n",
      "Epoch 223/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2123 - accuracy: 0.9308 - val_loss: 4.0193 - val_accuracy: 0.3973\n",
      "Epoch 224/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2176 - accuracy: 0.9289 - val_loss: 4.0823 - val_accuracy: 0.3946\n",
      "Epoch 225/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2228 - accuracy: 0.9275 - val_loss: 4.0099 - val_accuracy: 0.3973\n",
      "Epoch 226/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2187 - accuracy: 0.9280 - val_loss: 3.9486 - val_accuracy: 0.3969\n",
      "Epoch 227/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2151 - accuracy: 0.9288 - val_loss: 3.9888 - val_accuracy: 0.3979\n",
      "Epoch 228/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2018 - accuracy: 0.9345 - val_loss: 4.0045 - val_accuracy: 0.3976\n",
      "Epoch 229/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2069 - accuracy: 0.9319 - val_loss: 4.0279 - val_accuracy: 0.3889\n",
      "Epoch 230/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.2083 - accuracy: 0.9311 - val_loss: 4.1089 - val_accuracy: 0.3897\n",
      "Epoch 231/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1965 - accuracy: 0.9343 - val_loss: 4.0568 - val_accuracy: 0.3980\n",
      "Epoch 232/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1980 - accuracy: 0.9350 - val_loss: 4.1843 - val_accuracy: 0.3889\n",
      "Epoch 233/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1957 - accuracy: 0.9355 - val_loss: 4.1420 - val_accuracy: 0.3953\n",
      "Epoch 234/300\n",
      "391/391 [==============================] - 37s 93ms/step - loss: 0.1917 - accuracy: 0.9372 - val_loss: 4.1086 - val_accuracy: 0.3914\n",
      "Epoch 235/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1936 - accuracy: 0.9365 - val_loss: 4.1804 - val_accuracy: 0.3934\n",
      "Epoch 236/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1954 - accuracy: 0.9365 - val_loss: 4.1533 - val_accuracy: 0.3893\n",
      "Epoch 237/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1870 - accuracy: 0.9378 - val_loss: 4.1553 - val_accuracy: 0.3918\n",
      "Epoch 238/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1904 - accuracy: 0.9380 - val_loss: 4.1364 - val_accuracy: 0.3923\n",
      "Epoch 239/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1853 - accuracy: 0.9400 - val_loss: 4.0936 - val_accuracy: 0.3972\n",
      "Epoch 240/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1879 - accuracy: 0.9377 - val_loss: 4.3189 - val_accuracy: 0.3890\n",
      "Epoch 241/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1752 - accuracy: 0.9425 - val_loss: 4.1469 - val_accuracy: 0.3912\n",
      "Epoch 242/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1795 - accuracy: 0.9410 - val_loss: 4.1536 - val_accuracy: 0.3941\n",
      "Epoch 243/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1745 - accuracy: 0.9434 - val_loss: 4.1900 - val_accuracy: 0.3906\n",
      "Epoch 244/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1754 - accuracy: 0.9417 - val_loss: 4.1005 - val_accuracy: 0.3972\n",
      "Epoch 245/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1699 - accuracy: 0.9441 - val_loss: 4.2561 - val_accuracy: 0.3961\n",
      "Epoch 246/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1650 - accuracy: 0.9459 - val_loss: 4.3785 - val_accuracy: 0.3909\n",
      "Epoch 247/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1729 - accuracy: 0.9421 - val_loss: 4.3760 - val_accuracy: 0.3874\n",
      "Epoch 248/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1670 - accuracy: 0.9451 - val_loss: 4.2908 - val_accuracy: 0.3898\n",
      "Epoch 249/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1675 - accuracy: 0.9443 - val_loss: 4.2185 - val_accuracy: 0.3973\n",
      "Epoch 250/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1662 - accuracy: 0.9461 - val_loss: 4.2315 - val_accuracy: 0.3930\n",
      "Epoch 251/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1603 - accuracy: 0.9463 - val_loss: 4.4323 - val_accuracy: 0.3878\n",
      "Epoch 252/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1590 - accuracy: 0.9486 - val_loss: 4.2371 - val_accuracy: 0.3971\n",
      "Epoch 253/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1665 - accuracy: 0.9450 - val_loss: 4.3213 - val_accuracy: 0.3913\n",
      "Epoch 254/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1532 - accuracy: 0.9493 - val_loss: 4.1992 - val_accuracy: 0.3951\n",
      "Epoch 255/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1661 - accuracy: 0.9459 - val_loss: 4.2843 - val_accuracy: 0.3946\n",
      "Epoch 256/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1526 - accuracy: 0.9496 - val_loss: 4.2764 - val_accuracy: 0.3931\n",
      "Epoch 257/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1530 - accuracy: 0.9499 - val_loss: 4.3089 - val_accuracy: 0.3939\n",
      "Epoch 258/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1548 - accuracy: 0.9479 - val_loss: 4.4398 - val_accuracy: 0.3954\n",
      "Epoch 259/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1513 - accuracy: 0.9510 - val_loss: 4.3557 - val_accuracy: 0.3957\n",
      "Epoch 260/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1513 - accuracy: 0.9504 - val_loss: 4.3477 - val_accuracy: 0.3961\n",
      "Epoch 261/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1440 - accuracy: 0.9526 - val_loss: 4.4651 - val_accuracy: 0.3900\n",
      "Epoch 262/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1497 - accuracy: 0.9498 - val_loss: 4.3330 - val_accuracy: 0.3996\n",
      "Epoch 263/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1504 - accuracy: 0.9503 - val_loss: 4.2593 - val_accuracy: 0.3916\n",
      "Epoch 264/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1513 - accuracy: 0.9508 - val_loss: 4.3598 - val_accuracy: 0.3909\n",
      "Epoch 265/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1447 - accuracy: 0.9520 - val_loss: 4.2837 - val_accuracy: 0.3936\n",
      "Epoch 266/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1447 - accuracy: 0.9525 - val_loss: 4.3945 - val_accuracy: 0.3920\n",
      "Epoch 267/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1317 - accuracy: 0.9572 - val_loss: 4.4549 - val_accuracy: 0.3912\n",
      "Epoch 268/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1449 - accuracy: 0.9524 - val_loss: 4.2820 - val_accuracy: 0.3928\n",
      "Epoch 269/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1415 - accuracy: 0.9537 - val_loss: 4.3656 - val_accuracy: 0.3927\n",
      "Epoch 270/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1321 - accuracy: 0.9559 - val_loss: 4.4170 - val_accuracy: 0.3889\n",
      "Epoch 271/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1464 - accuracy: 0.9524 - val_loss: 4.4148 - val_accuracy: 0.3952\n",
      "Epoch 272/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1345 - accuracy: 0.9558 - val_loss: 4.3916 - val_accuracy: 0.3933\n",
      "Epoch 273/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1326 - accuracy: 0.9567 - val_loss: 4.3752 - val_accuracy: 0.3940\n",
      "Epoch 274/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1348 - accuracy: 0.9561 - val_loss: 4.3796 - val_accuracy: 0.3938\n",
      "Epoch 275/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1287 - accuracy: 0.9573 - val_loss: 4.3284 - val_accuracy: 0.3948\n",
      "Epoch 276/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1267 - accuracy: 0.9583 - val_loss: 4.4096 - val_accuracy: 0.3952\n",
      "Epoch 277/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1297 - accuracy: 0.9590 - val_loss: 4.4183 - val_accuracy: 0.3991\n",
      "Epoch 278/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1272 - accuracy: 0.9585 - val_loss: 4.4217 - val_accuracy: 0.3919\n",
      "Epoch 279/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1280 - accuracy: 0.9590 - val_loss: 4.4505 - val_accuracy: 0.3924\n",
      "Epoch 280/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1241 - accuracy: 0.9598 - val_loss: 4.4693 - val_accuracy: 0.3924\n",
      "Epoch 281/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1275 - accuracy: 0.9579 - val_loss: 4.4477 - val_accuracy: 0.3944\n",
      "Epoch 282/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1234 - accuracy: 0.9600 - val_loss: 4.5241 - val_accuracy: 0.3911\n",
      "Epoch 283/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1285 - accuracy: 0.9578 - val_loss: 4.5058 - val_accuracy: 0.3909\n",
      "Epoch 284/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1238 - accuracy: 0.9580 - val_loss: 4.4338 - val_accuracy: 0.3891\n",
      "Epoch 285/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1185 - accuracy: 0.9620 - val_loss: 4.4631 - val_accuracy: 0.3933\n",
      "Epoch 286/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1225 - accuracy: 0.9600 - val_loss: 4.4523 - val_accuracy: 0.3943\n",
      "Epoch 287/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1241 - accuracy: 0.9594 - val_loss: 4.4913 - val_accuracy: 0.3930\n",
      "Epoch 288/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1222 - accuracy: 0.9604 - val_loss: 4.5329 - val_accuracy: 0.3921\n",
      "Epoch 289/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1187 - accuracy: 0.9605 - val_loss: 4.6224 - val_accuracy: 0.3917\n",
      "Epoch 290/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1172 - accuracy: 0.9609 - val_loss: 4.4417 - val_accuracy: 0.3924\n",
      "Epoch 291/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1144 - accuracy: 0.9621 - val_loss: 4.4923 - val_accuracy: 0.3978\n",
      "Epoch 292/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1160 - accuracy: 0.9625 - val_loss: 4.5138 - val_accuracy: 0.3951\n",
      "Epoch 293/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1158 - accuracy: 0.9630 - val_loss: 4.4634 - val_accuracy: 0.3923\n",
      "Epoch 294/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1150 - accuracy: 0.9614 - val_loss: 4.6400 - val_accuracy: 0.3946\n",
      "Epoch 295/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1101 - accuracy: 0.9634 - val_loss: 4.6639 - val_accuracy: 0.3909\n",
      "Epoch 296/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1237 - accuracy: 0.9593 - val_loss: 4.5114 - val_accuracy: 0.3931\n",
      "Epoch 297/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1075 - accuracy: 0.9648 - val_loss: 4.5132 - val_accuracy: 0.3931\n",
      "Epoch 298/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1081 - accuracy: 0.9637 - val_loss: 4.5441 - val_accuracy: 0.3951\n",
      "Epoch 299/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1067 - accuracy: 0.9654 - val_loss: 4.5813 - val_accuracy: 0.3918\n",
      "Epoch 300/300\n",
      "391/391 [==============================] - 37s 94ms/step - loss: 0.1159 - accuracy: 0.9614 - val_loss: 4.5612 - val_accuracy: 0.3961\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 300\n",
    "\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.8530067\n",
      "valid 0.39386200040578845\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import util\n",
    "# util.save_record(train_history.history, 'VGG.txt')\n",
    "util.show_acc('VGG.txt', 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
